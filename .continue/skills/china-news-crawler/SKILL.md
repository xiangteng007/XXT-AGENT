---
name: china-news-crawler
description: 中国新闻站点内容提取。支持微信公众号、今日头条、网易新闻、搜狐新闻、腾讯新闻。当用户需要提取中国新闻内容、抓取公众号文章、爬取新闻、或获取新闻JSON/Markdown时激活。
---

# China News Crawler Skill

从中国主流新闻平台提取文章内容，输出 JSON 和 Markdown 格式。

**独立可迁移**：本 Skill 包含所有必需代码，无外部依赖，可直接复制到其他项目使用。

## 支持平台

| 平台 | ID | URL 示例 |
|------|-----|----------|
| 微信公众号 | wechat | `https://mp.weixin.qq.com/s/xxxxx` |
| 今日头条 | toutiao | `https://www.toutiao.com/article/123456/` |
| 网易新闻 | netease | `https://www.163.com/news/article/ABC123.html` |
| 搜狐新闻 | sohu | `https://www.sohu.com/a/123456_789` |
| 腾讯新闻 | tencent | `https://news.qq.com/rain/a/20251016A07W8J00` |

## 使用方式

### 基本用法

```bash
# 提取新闻，自动检测平台，输出 JSON + Markdown
uv run .claude/skills/china-news-crawler/scripts/extract_news.py "URL"

# 指定输出目录
uv run .claude/skills/china-news-crawler/scripts/extract_news.py "URL" --output ./output

# 仅输出 JSON
uv run .claude/skills/china-news-crawler/scripts/extract_news.py "URL" --format json

# 仅输出 Markdown
uv run .claude/skills/china-news-crawler/scripts/extract_news.py "URL" --format markdown

# 列出支持的平台
uv run .claude/skills/china-news-crawler/scripts/extract_news.py --list-platforms
```

### 输出文件

脚本默认输出两种格式到指定目录（默认 `./output`）：
- `{news_id}.json` - 结构化 JSON 数据
- `{news_id}.md` - Markdown 格式文章

## 工作流程

1. **接收 URL** - 用户提供新闻链接
2. **平台检测** - 自动识别平台类型
3. **内容提取** - 调用对应爬虫获取并解析内容
4. **格式转换** - 生成 JSON 和 Markdown
5. **输出文件** - 保存到指定目录

## 输出格式

### JSON 结构

```json
{
  "title": "文章标题",
  "news_url": "原始链接",
  "news_id": "文章ID",
  "meta_info": {
    "author_name": "作者/来源",
    "author_url": "",
    "publish_time": "2024-01-01 12:00"
  },
  "contents": [
    {"type": "text", "content": "段落文本", "desc": ""},
    {"type": "image", "content": "https://...", "desc": ""},
    {"type": "video", "content": "https://...", "desc": ""}
  ],
  "texts": ["段落1", "段落2"],
  "images": ["图片URL1", "图片URL2"],
  "videos": []
}
```

### Markdown 结构

```markdown
# 文章标题

## 文章信息
**作者**: xxx
**发布时间**: 2024-01-01 12:00
**原文链接**: [链接](URL)

---

## 正文内容

段落内容...

![图片](URL)

---

## 媒体资源
### 图片 (N)
1. URL1
2. URL2
```

## 使用示例

### 提取微信公众号文章

```bash
uv run .claude/skills/china-news-crawler/scripts/extract_news.py \
  "https://mp.weixin.qq.com/s/ebMzDPu2zMT_mRgYgtL6eQ"
```

输出:
```
[INFO] Platform detected: wechat (微信公众号)
[INFO] Extracting content...
[INFO] Title: 文章标题
[INFO] Author: 公众号名称
[INFO] Text paragraphs: 15
[INFO] Images: 3
[SUCCESS] Saved: ./output/ebMzDPu2zMT_mRgYgtL6eQ.json
[SUCCESS] Saved: ./output/ebMzDPu2zMT_mRgYgtL6eQ.md
```

### 提取今日头条文章

```bash
uv run .claude/skills/china-news-crawler/scripts/extract_news.py \
  "https://www.toutiao.com/article/7434425099895210546/"
```

## 依赖要求

本 Skill 需要以下 Python 包（通常已在主项目中安装）：
- parsel
- pydantic
- requests
- curl-cffi
- tenacity
- demjson3

## 错误处理

| 错误类型 | 说明 | 解决方案 |
|----------|------|----------|
| `无法识别该平台` | URL 不匹配任何支持的平台 | 检查 URL 是否正确 |
| `平台不支持` | 非中国站点 | 本 Skill 仅支持中国新闻站点 |
| `提取失败` | 网络错误或页面结构变化 | 重试或检查 URL 有效性 |

## 注意事项

- 仅用于教育和研究目的
- 不要进行大规模爬取
- 尊重目标网站的 robots.txt 和服务条款
- 微信公众号可能需要有效的 Cookie（当前默认配置通常可用）

## 目录结构

```
china-news-crawler/
├── SKILL.md                      # [必需] Skill 定义文件
├── references/
│   └── platform-patterns.md      # 平台 URL 模式说明
└── scripts/
    ├── extract_news.py           # CLI 入口脚本
    ├── models.py                 # 数据模型
    ├── detector.py               # 平台检测
    ├── formatter.py              # Markdown 格式化
    └── crawlers/                 # 爬虫模块
        ├── __init__.py
        ├── base.py               # BaseNewsCrawler 基类
        ├── fetchers.py           # HTTP 获取策略
        ├── wechat.py             # 微信公众号
        ├── toutiao.py            # 今日头条
        ├── netease.py            # 网易新闻
        ├── sohu.py               # 搜狐新闻
        └── tencent.py            # 腾讯新闻
```

## 参考

- [平台 URL 模式说明](references/platform-patterns.md)
